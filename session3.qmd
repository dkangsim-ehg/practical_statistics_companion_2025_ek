# Session 3: Descriptive Statistics {#sec-descriptive}

Descriptive statistics are the foundation of data analysis. They help us understand what our data looks like before we move on to more complex analyses. In medical research, good descriptive statistics are essential for understanding patient characteristics, treatment outcomes, and study populations.

## Learning Objectives

By the end of this session, you will be able to:

- Calculate and interpret measures of central tendency
- Understand and compute measures of variability
- Create appropriate visualizations for different data types
- Compare groups using descriptive statistics
- Recognize when descriptive statistics may be misleading

## Overview of Descriptive Statistics

Descriptive statistics serve two main purposes in medical research:

1. **Summarize data**: Reduce large datasets to key characteristics
2. **Describe populations**: Help readers understand study participants and outcomes

Let's start with our student performance dataset (analogous to patient outcome data):

```{webr-r}
# Our student dataset was created in global setup - let's examine it
cat("=== STUDENT PERFORMANCE DATASET ===\n")
cat("Total students:", nrow(student_data), "\n")
cat("Variables:", ncol(student_data), "\n\n")

# Quick overview
cat("Dataset structure:\n")
glimpse(student_data)

# Basic summary
cat("\n=== QUICK SUMMARY ===\n")
student_summary <- student_data %>%
  summarise(
    n = n(),
    mean_age = round(mean(age), 1),
    age_range = paste(min(age), "to", max(age)),
    female_pct = round(mean(gender == "Female") * 100, 1),
    mean_math = round(mean(math_score), 1),
    mean_science = round(mean(science_score), 1),
    mean_english = round(mean(english_score), 1)
  )

print(student_summary)
```

## Measures of Central Tendency

Central tendency describes the "typical" or "average" value in your dataset. The choice of measure depends on your data type and distribution shape.

### The Mean, Median, and Mode

```{webr-r}
# Calculate all three measures for our academic scores
central_tendency <- student_data %>%
  select(math_score, science_score, english_score) %>%
  summarise(
    across(everything(), 
           list(
             n = ~n(),
             mean = ~round(mean(.x, na.rm = TRUE), 2),
             median = ~round(median(.x, na.rm = TRUE), 2),
             # Mode calculation (most frequent value)
             mode = ~{
               tbl <- table(round(.x))
               as.numeric(names(tbl)[which.max(tbl)])
             },
             min = ~round(min(.x, na.rm = TRUE), 1),
             max = ~round(max(.x, na.rm = TRUE), 1)
           ),
           .names = "{.col}_{.fn}")
  ) %>%
  pivot_longer(everything(), names_to = "stat_var", values_to = "value") %>%
  separate(stat_var, into = c("subject", "statistic"), sep = "_(?=[^_]+$)") %>%
  pivot_wider(names_from = statistic, values_from = value)

print(central_tendency)
```

### Manual Calculation Example

Understanding how statistics are calculated helps you interpret them better:

```{webr-r}
# Manual calculation for math score mean
cat("=== MANUAL CALCULATION: MATH SCORE MEAN ===\n")

math_scores <- student_data$math_score
n_students <- length(math_scores)
sum_scores <- sum(math_scores)
calculated_mean <- sum_scores / n_students

cat(sprintf("Step 1: Add all scores = %.1f\n", sum_scores))
cat(sprintf("Step 2: Count observations = %d\n", n_students))
cat(sprintf("Step 3: Divide sum by count = %.1f ÷ %d = %.2f\n", 
            sum_scores, n_students, calculated_mean))

# Verify with R's built-in function
r_mean <- mean(math_scores)
cat(sprintf("R's mean() function = %.2f\n", r_mean))
cat(sprintf("Difference = %.10f (should be ~0)\n", abs(calculated_mean - r_mean)))

# Show first 10 scores for transparency
cat("\nFirst 10 math scores:", paste(round(head(math_scores, 10), 1), collapse = ", "))
```

### When to Use Each Measure

The choice between mean, median, and mode depends on your data characteristics:

```{webr-r}
# Create different distribution shapes to demonstrate
set.seed(789)

distribution_examples <- tibble(
  # Normal distribution (symmetric)
  normal = rnorm(1000, mean = 75, sd = 10),
  
  # Right-skewed (like income, length of stay)
  right_skewed = rgamma(1000, shape = 2, rate = 0.03),
  
  # Left-skewed (like test scores on easy exam)
  left_skewed = 100 - rgamma(1000, shape = 2, rate = 0.03)
) %>%
  # Ensure reasonable ranges
  mutate(
    normal = pmax(0, pmin(100, normal)),
    right_skewed = pmax(0, pmin(100, right_skewed)),
    left_skewed = pmax(0, pmin(100, left_skewed))
  ) %>%
  pivot_longer(everything(), names_to = "distribution_type", values_to = "value")

# Calculate central tendency for each distribution
skew_comparison <- distribution_examples %>%
  group_by(distribution_type) %>%
  summarise(
    mean_val = round(mean(value), 2),
    median_val = round(median(value), 2),
    difference = round(mean_val - median_val, 2),
    .groups = 'drop'
  ) %>%
  mutate(
    interpretation = case_when(
      abs(difference) < 1 ~ "Symmetric - use mean",
      difference > 1 ~ "Right skewed - consider median", 
      difference < -1 ~ "Left skewed - consider median"
    )
  )

cat("=== CENTRAL TENDENCY BY DISTRIBUTION SHAPE ===\n")
print(skew_comparison)

# Visualize the distributions
distribution_plot <- distribution_examples %>%
  ggplot(aes(x = value, fill = distribution_type)) +
  geom_histogram(bins = 30, alpha = 0.7, color = "white") +
  geom_vline(data = skew_comparison, aes(xintercept = mean_val), 
             color = "red", linetype = "dashed", linewidth = 1) +
  geom_vline(data = skew_comparison, aes(xintercept = median_val), 
             color = "blue", linetype = "solid", linewidth = 1) +
  facet_wrap(~distribution_type, scales = "free_y", ncol = 1) +
  labs(title = "Central Tendency in Different Distribution Shapes",
       subtitle = "Red dashed = Mean, Blue solid = Median",
       x = "Value", y = "Frequency") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_viridis_d()

print(distribution_plot)
```

::: {.callout-important}
## Clinical Application
In medical research:
- **Use the mean** when data is roughly symmetric (e.g., height, blood pressure in healthy populations)
- **Use the median** when data is skewed (e.g., length of hospital stay, income, some lab values)
- **Report both** when unsure, as they provide different insights
:::

## Measures of Spread (Variability)

Measures of central tendency only tell part of the story. Two groups can have the same mean but very different variability. In clinical trials, understanding variability is crucial for interpreting treatment effects.

### Range, Variance, and Standard Deviation

```{webr-r}
# Calculate comprehensive measures of spread
spread_measures <- student_data %>%
  select(math_score, science_score, english_score) %>%
  summarise(
    across(everything(),
           list(
             # Basic measures
             n = ~n(),
             mean = ~round(mean(.x), 2),
             
             # Measures of spread
             range = ~round(max(.x) - min(.x), 1),
             variance = ~round(var(.x), 2),
             std_dev = ~round(sd(.x), 2),
             iqr = ~round(IQR(.x), 2),
             
             # Quartiles
             q1 = ~round(quantile(.x, 0.25), 2),
             q3 = ~round(quantile(.x, 0.75), 2),
             
             # Coefficient of variation (for comparing variability)
             cv = ~round((sd(.x) / mean(.x)) * 100, 1)
           ),
           .names = "{.col}_{.fn}")
  ) %>%
  pivot_longer(everything(), names_to = "stat_var", values_to = "value") %>%
  separate(stat_var, into = c("subject", "statistic"), sep = "_(?=[^_]+$)") %>%
  pivot_wider(names_from = statistic, values_from = value)

print(spread_measures)
```

### Manual Variance Calculation

Understanding the calculation helps interpret the meaning:

```{webr-r}
# Step-by-step variance calculation for math scores
cat("=== MANUAL VARIANCE CALCULATION ===\n")

math_scores <- student_data$math_score
n <- length(math_scores)
mean_score <- mean(math_scores)

# Calculate deviations from mean
deviations <- math_scores - mean_score
squared_deviations <- deviations^2
sum_squared_dev <- sum(squared_deviations)

# Sample variance (dividing by n-1)
sample_variance <- sum_squared_dev / (n - 1)
sample_sd <- sqrt(sample_variance)

cat(sprintf("Step 1: Calculate mean = %.2f\n", mean_score))
cat(sprintf("Step 2: Find deviations from mean\n"))
cat(sprintf("Step 3: Square the deviations\n"))
cat(sprintf("Step 4: Sum squared deviations = %.1f\n", sum_squared_dev))
cat(sprintf("Step 5: Divide by (n-1) = %.1f ÷ (%d-1) = %.2f\n", 
            sum_squared_dev, n, sample_variance))
cat(sprintf("Step 6: Standard deviation = √%.2f = %.2f\n", 
            sample_variance, sample_sd))

# Show why we divide by n-1 (degrees of freedom)
cat(sprintf("\nNote: We use n-1 = %d (not n = %d) for sample variance\n", n-1, n))
cat("This corrects for the fact that we estimated the mean from the data.\n")

# Show some example deviations
example_deviations <- tibble(
  Score = head(math_scores, 8),
  Deviation = head(deviations, 8),
  Squared_Dev = head(squared_deviations, 8)
) %>%
  mutate(across(where(is.numeric), ~round(.x, 2)))

cat("\nExample calculations for first 8 students:\n")
print(example_deviations)
```

### Interpreting Standard Deviation

Standard deviation has a special relationship with the normal distribution:

```{webr-r}
# Demonstrate the empirical rule (68-95-99.7 rule)
math_mean <- mean(student_data$math_score)
math_sd <- sd(student_data$math_score)

# Calculate boundaries
boundaries <- tibble(
  Range = c("Mean ± 1 SD", "Mean ± 2 SD", "Mean ± 3 SD"),
  Lower = c(math_mean - math_sd, math_mean - 2*math_sd, math_mean - 3*math_sd),
  Upper = c(math_mean + math_sd, math_mean + 2*math_sd, math_mean + 3*math_sd),
  Expected_Pct = c("~68%", "~95%", "~99.7%")
) %>%
  mutate(
    Lower = round(Lower, 1),
    Upper = round(Upper, 1)
  )

# Calculate actual percentages in our data
actual_pct <- tibble(
  Range = c("Mean ± 1 SD", "Mean ± 2 SD", "Mean ± 3 SD"),
  Actual_Pct = c(
    mean(abs(student_data$math_score - math_mean) <= math_sd) * 100,
    mean(abs(student_data$math_score - math_mean) <= 2*math_sd) * 100,
    mean(abs(student_data$math_score - math_mean) <= 3*math_sd) * 100
  )
) %>%
  mutate(Actual_Pct = paste0(round(Actual_Pct, 0), "%"))

empirical_rule <- boundaries %>%
  left_join(actual_pct, by = "Range")

cat("=== THE EMPIRICAL RULE (68-95-99.7 RULE) ===\n")
cat(sprintf("Math scores: Mean = %.1f, SD = %.1f\n\n", math_mean, math_sd))
print(empirical_rule)

# Visualize the empirical rule
empirical_plot <- student_data %>%
  ggplot(aes(x = math_score)) +
  geom_histogram(bins = 20, alpha = 0.7, fill = "lightblue", color = "white") +
  # Mark mean
  geom_vline(xintercept = math_mean, color = "red", linewidth = 1.5) +
  # Mark ±1 SD
  geom_vline(xintercept = c(math_mean - math_sd, math_mean + math_sd), 
             color = "orange", linetype = "dashed", linewidth = 1) +
  # Mark ±2 SD  
  geom_vline(xintercept = c(math_mean - 2*math_sd, math_mean + 2*math_sd), 
             color = "green", linetype = "dotted", linewidth = 1) +
  labs(title = "The Empirical Rule: Standard Deviation and Normal Distribution",
       subtitle = "Red = Mean, Orange = ±1 SD, Green = ±2 SD",
       x = "Math Score", y = "Frequency") +
  theme_minimal()

print(empirical_plot)
```

::: {.callout-tip}
## Clinical Interpretation
In medical research, standard deviation helps identify:
- **Normal vs. abnormal values**: Values beyond 2-3 SDs may warrant investigation
- **Treatment effects**: Is the improvement larger than typical random variation?
- **Sample size planning**: Larger SD requires larger samples to detect effects
:::

### Coefficient of Variation

When comparing variability across different scales or groups:

```{webr-r}
# Compare variability across different groups using CV
cv_comparison <- student_data %>%
  group_by(gender) %>%
  summarise(
    across(c(math_score, science_score, english_score),
           list(
             n = ~n(),
             mean = ~round(mean(.x), 1),
             sd = ~round(sd(.x), 1),
             cv = ~round((sd(.x) / mean(.x)) * 100, 1)
           ),
           .names = "{.col}_{.fn}"),
    .groups = 'drop'
  ) %>%
  pivot_longer(cols = -gender, names_to = "stat_var", values_to = "value") %>%
  separate(stat_var, into = c("subject", "statistic"), sep = "_(?=[^_]+$)") %>%
  pivot_wider(names_from = statistic, values_from = value)

cat("=== COEFFICIENT OF VARIATION BY GENDER ===\n")
print(cv_comparison)

cat("\nInterpretation of Coefficient of Variation (CV):\n")
cat("• CV < 15%: Low variability (homogeneous group)\n")
cat("• CV 15-35%: Moderate variability\n")
cat("• CV > 35%: High variability (heterogeneous group)\n")
cat("\nCV allows comparison of variability across different scales:\n")
cat("Example: Can compare variability in blood pressure (mmHg) vs. heart rate (bpm)\n")

# Show why CV is useful
cv_example <- tibble(
  Measurement = c("Heart Rate (bpm)", "Systolic BP (mmHg)", "Temperature (°C)"),
  Mean = c(72, 120, 37.0),
  SD = c(8, 15, 0.5),
  CV = round((c(8, 15, 0.5) / c(72, 120, 37.0)) * 100, 1)
)

cat("\n=== WHY COEFFICIENT OF VARIATION MATTERS ===\n")
print(cv_example)
cat("\nWithout CV: SD of 15 (BP) seems larger than SD of 8 (HR)\n")
cat("With CV: BP is actually less variable (12.5%) than HR (11.1%)\n")
```

## Descriptive Statistics by Groups

In medical research, we often need to compare groups (treatment vs. control, male vs. female, etc.):

```{webr-r}
# Comprehensive descriptive statistics by year in school
descriptives_by_year <- student_data %>%
  group_by(year_in_school) %>%
  summarise(
    n = n(),
    
    # Demographics
    mean_age = round(mean(age), 1),
    female_pct = round(mean(gender == "Female") * 100, 1),
    
    # Academic performance
    math_mean = round(mean(math_score), 1),
    math_sd = round(sd(math_score), 1),
    science_mean = round(mean(science_score), 1),
    science_sd = round(sd(science_score), 1),
    english_mean = round(mean(english_score), 1),
    english_sd = round(sd(english_score), 1),
    
    # Study habits
    study_hours_mean = round(mean(study_hours_week), 1),
    study_hours_sd = round(sd(study_hours_week), 1),
    
    .groups = 'drop'
  )

cat("=== DESCRIPTIVE STATISTICS BY YEAR IN SCHOOL ===\n")
print(descriptives_by_year)

# Create publication-ready summary table
publication_table <- student_data %>%
  group_by(gender) %>%
  summarise(
    `N` = n(),
    `Age (years)` = paste0(round(mean(age), 1), " ± ", round(sd(age), 1)),
    `Math Score` = paste0(round(mean(math_score), 1), " ± ", round(sd(math_score), 1)),
    `Science Score` = paste0(round(mean(science_score), 1), " ± ", round(sd(science_score), 1)),
    `English Score` = paste0(round(mean(english_score), 1), " ± ", round(sd(english_score), 1)),
    .groups = 'drop'
  )

cat("\n=== PUBLICATION-STYLE TABLE (Mean ± SD) ===\n")
print(publication_table)
```

::: {.callout-note}
## Table Format Standards
Medical journals typically report continuous variables as "Mean ± SD" or "Median (IQR)" depending on distribution shape. Categorical variables are reported as "N (%)" or just percentages.
:::

## Data Visualization for Descriptive Statistics

Visualizations help readers quickly understand your data patterns:

### Distribution Plots

```{webr-r}
# Create comprehensive visualization of score distributions
score_data <- student_data %>%
  select(math_score, science_score, english_score) %>%
  pivot_longer(everything(), names_to = "subject", values_to = "score") %>%
  mutate(subject = str_replace(subject, "_score", "") %>% str_to_title())

# Calculate means for overlay
score_means <- score_data %>% 
  group_by(subject) %>% 
  summarise(mean_score = mean(score), .groups = 'drop')

# Histogram with overlaid statistics
distribution_plot <- score_data %>%
  ggplot(aes(x = score, fill = subject)) +
  geom_histogram(bins = 20, alpha = 0.7, color = "white") +
  geom_vline(data = score_means,
             aes(xintercept = mean_score), 
             color = "red", linetype = "dashed", linewidth = 1) +
  facet_wrap(~subject, ncol = 1, scales = "free_y") +
  labs(title = "Distribution of Academic Scores",
       subtitle = "Red dashed line shows mean for each subject",
       x = "Score", y = "Frequency",
       caption = "Data shows roughly normal distributions with slight variations") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_viridis_d()

print(distribution_plot)

# Summary statistics for each subject
distribution_stats <- score_data %>%
  group_by(subject) %>%
  summarise(
    n = n(),
    mean = round(mean(score), 1),
    median = round(median(score), 1),
    sd = round(sd(score), 1),
    min = round(min(score), 1),
    max = round(max(score), 1),
    .groups = 'drop'
  )

cat("=== DISTRIBUTION SUMMARY STATISTICS ===\n")
print(distribution_stats)
```

### Box Plots for Group Comparisons

Box plots are excellent for comparing groups and showing distribution shape:

```{webr-r}
# Create box plots comparing scores by gender
gender_score_data <- student_data %>%
  select(gender, math_score, science_score, english_score) %>%
  pivot_longer(cols = c(math_score, science_score, english_score), 
               names_to = "subject", values_to = "score") %>%
  mutate(subject = str_replace(subject, "_score", "") %>% str_to_title())

boxplot_comparison <- gender_score_data %>%
  ggplot(aes(x = subject, y = score, fill = gender)) +
  geom_boxplot(alpha = 0.8, outlier.alpha = 0.6, width = 0.7) +
  # Add individual points (optional - can be overwhelming with large datasets)
  # geom_jitter(width = 0.2, alpha = 0.3, size = 0.5) +
  stat_summary(fun = mean, geom = "point", color = "red", size = 2, 
               position = position_dodge(width = 0.7)) +
  labs(title = "Score Distribution by Subject and Gender",
       subtitle = "Boxes show median and quartiles, red dots show means",
       x = "Subject", y = "Score", fill = "Gender",
       caption = "Outliers shown as individual points beyond whiskers") +
  scale_fill_viridis_d(alpha = 0.8) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(boxplot_comparison)

# Interpret the box plots
cat("=== HOW TO READ BOX PLOTS ===\n")
cat("• Box center line = Median (50th percentile)\n")
cat("• Box edges = Q1 (25th) and Q3 (75th percentiles)\n") 
cat("• Box height = Interquartile Range (IQR = Q3 - Q1)\n")
cat("• Whiskers = Extend to most extreme values within 1.5×IQR\n")
cat("• Individual points = Outliers beyond whiskers\n")
cat("• Red dots = Group means\n")
```

### Correlation Analysis

Understanding relationships between variables:

```{webr-r}
# Correlation analysis between academic subjects
correlation_data <- student_data %>%
  select(math_score, science_score, english_score, study_hours_week, age)

# Calculate correlation matrix manually using dplyr
correlations <- tibble(
  Variable_Pair = c("Math ↔ Science", "Math ↔ English", "Science ↔ English", 
                   "Math ↔ Study Hours", "Science ↔ Study Hours", "English ↔ Study Hours"),
  Correlation = c(
    cor(correlation_data$math_score, correlation_data$science_score),
    cor(correlation_data$math_score, correlation_data$english_score),
    cor(correlation_data$science_score, correlation_data$english_score),
    cor(correlation_data$math_score, correlation_data$study_hours_week),
    cor(correlation_data$science_score, correlation_data$study_hours_week),
    cor(correlation_data$english_score, correlation_data$study_hours_week)
  )
) %>%
  mutate(
    Correlation = round(Correlation, 3),
    Strength = case_when(
      abs(Correlation) < 0.3 ~ "Weak",
      abs(Correlation) < 0.7 ~ "Moderate", 
      TRUE ~ "Strong"
    ),
    Direction = ifelse(Correlation > 0, "Positive", "Negative")
  )

cat("=== CORRELATION ANALYSIS ===\n")
print(correlations)

# Create scatterplot for strongest correlation
strongest_corr <- max(abs(correlations$Correlation))
math_science_cor <- cor(student_data$math_score, student_data$science_score)

correlation_plot <- student_data %>%
  ggplot(aes(x = math_score, y = science_score)) +
  geom_point(alpha = 0.6, color = "steelblue", size = 2) +
  geom_smooth(method = "lm", se = TRUE, color = "red", fill = "pink", alpha = 0.3) +
  labs(title = "Correlation: Math vs Science Scores",
       subtitle = sprintf("Pearson correlation coefficient (r) = %.3f", math_science_cor),
       x = "Math Score", y = "Science Score",
       caption = "Red line shows linear trend with 95% confidence band") +
  theme_minimal() +
  # Add correlation interpretation
  annotate("text", x = 50, y = 95, 
           label = paste("Interpretation:", 
                        ifelse(abs(math_science_cor) > 0.7, "Strong", 
                               ifelse(abs(math_science_cor) > 0.3, "Moderate", "Weak")),
                        "positive correlation"),
           hjust = 0, color = "darkblue", size = 3)

print(correlation_plot)
```

::: {.callout-important}
## Correlation Interpretation
- **r = 0**: No linear relationship
- **0 < |r| < 0.3**: Weak relationship  
- **0.3 ≤ |r| < 0.7**: Moderate relationship
- **0.7 ≤ |r| < 1**: Strong relationship
- **r = ±1**: Perfect linear relationship

**Remember**: Correlation ≠ Causation!
:::

## Advanced Descriptive Techniques

### Five-Number Summary and IQR

```{webr-r}
# Create five-number summaries
five_number_summary <- student_data %>%
  select(math_score, science_score, english_score) %>%
  summarise(
    across(everything(),
           list(
             min = ~min(.x),
             q1 = ~quantile(.x, 0.25),
             median = ~median(.x),
             q3 = ~quantile(.x, 0.75),
             max = ~max(.x),
             iqr = ~IQR(.x)
           ),
           .names = "{.col}_{.fn}")
  ) %>%
  pivot_longer(everything(), names_to = "stat_var", values_to = "value") %>%
  separate(stat_var, into = c("subject", "statistic"), sep = "_(?=[^_]+$)") %>%
  pivot_wider(names_from = statistic, values_from = value) %>%
  mutate(across(where(is.numeric), ~round(.x, 1)))

cat("=== FIVE-NUMBER SUMMARY ===\n")
print(five_number_summary)

# Identify potential outliers using IQR method
outlier_analysis <- student_data %>%
  select(student_id, math_score) %>%
  mutate(
    q1 = quantile(math_score, 0.25),
    q3 = quantile(math_score, 0.75),
    iqr = q3 - q1,
    lower_fence = q1 - 1.5 * iqr,
    upper_fence = q3 + 1.5 * iqr,
    is_outlier = math_score < lower_fence | math_score > upper_fence
  ) %>%
  filter(is_outlier) %>%
  select(student_id, math_score, lower_fence, upper_fence)

cat("\n=== POTENTIAL OUTLIERS (using IQR method) ===\n")
if(nrow(outlier_analysis) > 0) {
  print(outlier_analysis)
} else {
  cat("No outliers detected using IQR method\n")
}

cat("\nOutlier detection rule: Values beyond Q1 - 1.5×IQR or Q3 + 1.5×IQR\n")
```

### Grouped Analysis with Multiple Variables

```{webr-r}
# Comprehensive analysis by multiple grouping variables
multi_group_analysis <- student_data %>%
  # Create meaningful age groups
  mutate(age_group = cut(age, breaks = c(17, 20, 22, 25), 
                        labels = c("18-20", "21-22", "23-25"))) %>%
  group_by(gender, age_group) %>%
  summarise(
    n = n(),
    mean_math = round(mean(math_score), 1),
    mean_science = round(mean(science_score), 1),
    mean_english = round(mean(english_score), 1),
    overall_gpa = round((math_score + science_score + english_score) / 3, 1) %>% mean(),
    .groups = 'drop'
  ) %>%
  filter(n >= 5)  # Only show groups with adequate sample size

cat("=== ACADEMIC PERFORMANCE BY GENDER AND AGE GROUP ===\n")
print(multi_group_analysis)

# Create heatmap visualization
heatmap_data <- multi_group_analysis %>%
  select(gender, age_group, overall_gpa) %>%
  pivot_wider(names_from = age_group, values_from = overall_gpa)

cat("\n=== OVERALL GPA BY DEMOGRAPHIC GROUPS ===\n")
print(heatmap_data)
```

## Summary and Key Findings

```{webr-r}
# Create comprehensive summary of key findings
final_summary <- tibble(
  Statistic = c("Sample Size", "Age Range", "Gender Distribution", 
                "Math Score", "Science Score", "English Score",
                "Strongest Correlation", "Most Variable Subject"),
  Value = c(
    paste(nrow(student_data), "students"),
    paste(min(student_data$age), "-", max(student_data$age), "years"),
    paste0(round(mean(student_data$gender == "Female") * 100, 0), "% female"),
    paste0(round(mean(student_data$math_score), 1), " ± ", 
           round(sd(student_data$math_score), 1)),
    paste0(round(mean(student_data$science_score), 1), " ± ", 
           round(sd(student_data$science_score), 1)),
    paste0(round(mean(student_data$english_score), 1), " ± ", 
           round(sd(student_data$english_score), 1)),
    paste("Math ↔ Science (r =", round(math_science_cor, 3), ")"),
    paste("English (CV =", 
          round((sd(student_data$english_score) / mean(student_data$english_score)) * 100, 1), "%)")
  )
)

cat("=== STUDY SUMMARY: KEY FINDINGS ===\n")
print(final_summary)

# Final visualization: Summary dashboard
summary_viz <- student_data %>%
  ggplot(aes(x = math_score, y = science_score)) +
  geom_point(aes(color = gender, size = english_score), alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
  labs(title = "Academic Performance Overview",
       subtitle = paste("Strong correlation between Math and Science (r =", 
                        round(math_science_cor, 3), ")"),
       x = "Math Score", y = "Science Score", 
       color = "Gender", size = "English Score",
       caption = "Point size represents English score; dashed line shows overall trend") +
  scale_color_viridis_d() +
  scale_size_continuous(range = c(1, 4)) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(summary_viz)
```

## Key Takeaways

::: {.callout-tip}
## Remember These Principles

**1. Choose appropriate statistics for your data type:**
- Nominal/Ordinal: Frequencies, percentages, mode
- Continuous: Mean, SD for symmetric; median, IQR for skewed

**2. Always report sample sizes:**
- Small samples (n < 30) require different approaches
- Unequal group sizes affect interpretation

**3. Describe variability, not just central tendency:**
- SD tells you about consistency of measurements
- CV allows comparison across different scales

**4. Use appropriate visualizations:**
- Bar charts for categorical data
- Histograms for distributions
- Box plots for group comparisons
- Scatterplots for relationships

**5. Consider clinical significance alongside statistical measures:**
- A statistically significant difference may not be clinically meaningful
- Context matters in medical research
:::

## Next Steps

You now have the foundation for describing and summarizing medical research data. These skills prepare you for:

- **Inferential statistics**: Testing hypotheses about population differences
- **Regression analysis**: Modeling relationships between variables  
- **Clinical trial analysis**: Comparing treatment outcomes
- **Epidemiological research**: Understanding disease patterns

In future sessions, you'll learn how to move from describing your sample to making inferences about the broader population.

---

*Descriptive statistics are the foundation of all data analysis. Master these concepts, and you'll be able to effectively communicate your research findings and prepare for more advanced statistical methods.*
